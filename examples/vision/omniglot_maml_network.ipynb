{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/debo/learn2learn/')\n",
    "sys.path.append('../../learn2learn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  master\u001b[m\r\n",
      "  omniglot\u001b[m\r\n",
      "* \u001b[32mprototypical_network\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "from utils import clone_module\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class BaseLearner(nn.Module):\n",
    "\n",
    "    def __init__(self, module=None):\n",
    "        super(BaseLearner, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        try:\n",
    "            return super(BaseLearner, self).__getattr__(attr)\n",
    "        except AttributeError:\n",
    "            return getattr(self.__dict__['_modules']['module'], attr)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.module(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maml_update(model, lr, grads):\n",
    "    \"\"\"\n",
    "    Performs a MAML update on model using grads and lr.\n",
    "    The function re-routes the Python object, thus avoiding in-place\n",
    "    operations. However, it seems like PyTorch handles in-place operations\n",
    "    fairly well.\n",
    "    \n",
    "    NOTE: The model itself is updated in-place (no deepcopy), but the\n",
    "          parameters' tensors are not.\n",
    "\n",
    "    NOTE: grads is None -> Don't set the gradients.\n",
    "    \"\"\"\n",
    "    if grads is not None:\n",
    "        params = list(model.parameters())\n",
    "        if not len(grads) == len(list(params)):\n",
    "            msg = 'WARNING:maml_update(): Parameters and gradients have different length. ('\n",
    "            msg += str(len(params)) + ' vs ' + str(len(grads)) + ')'\n",
    "            print(msg)\n",
    "        for p, g in zip(params, grads):\n",
    "            p.grad = g\n",
    "\n",
    "    # Update the params\n",
    "    for param_key in model._parameters:\n",
    "        p = model._parameters[param_key]\n",
    "        if p is not None and p.grad is not None:\n",
    "            model._parameters[param_key] = p - lr * p.grad\n",
    "\n",
    "    # Second, handle the buffers if necessary\n",
    "    for buffer_key in model._buffers:\n",
    "        buff = model._buffers[buffer_key]\n",
    "        if buff is not None and buff.grad is not None:\n",
    "            model._buffers[buffer_key] = buff - lr * buff.grad\n",
    "\n",
    "    # Then, recurse for each submodule\n",
    "    for module_key in model._modules:\n",
    "        model._modules[module_key] = maml_update(model._modules[module_key],\n",
    "                                                 lr=lr,\n",
    "                                                 grads=None)\n",
    "    return model\n",
    "\n",
    "\n",
    "class MAML(BaseLearner):\n",
    "\n",
    "    def __init__(self, model, lr, first_order=False):\n",
    "        super(MAML, self).__init__()\n",
    "        self.module = model\n",
    "        self.lr = lr\n",
    "        self.first_order = first_order\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.module(*args, **kwargs)\n",
    "\n",
    "    def adapt(self, loss, first_order=None):\n",
    "        if first_order is None:\n",
    "            first_order = self.first_order\n",
    "        second_order = not first_order\n",
    "        gradients = grad(loss,\n",
    "                         self.module.parameters(),\n",
    "                         retain_graph=second_order,\n",
    "                         create_graph=second_order)\n",
    "        self.module = maml_update(self.module, self.lr, gradients)\n",
    "\n",
    "    def clone(self, first_order=None):\n",
    "        if first_order is None:\n",
    "            first_order = self.first_order\n",
    "        return MAML(clone_module(self.module),\n",
    "                    lr=self.lr,\n",
    "                    first_order=first_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import learn2learn as l2l\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "\n",
    "def truncated_normal_(tensor, mean=0.0, std=1.0):\n",
    "    # PT doesn't have truncated normal.\n",
    "    # https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/18\n",
    "    values = truncnorm.rvs(-2, 2, size=tensor.shape)\n",
    "    values = mean + std * values\n",
    "    tensor.copy_(th.from_numpy(values))\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def maml_fc_init_(module):\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        truncated_normal_(module.weight.data, mean=0.0, std=0.01)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        nn.init.constant_(module.bias.data, 0.0)\n",
    "    return module\n",
    "\n",
    "\n",
    "class MAMLLinearBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MAMLLinearBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.normalize = nn.BatchNorm1d(output_size,\n",
    "                                        affine=True,\n",
    "                                        momentum=0.999,\n",
    "                                        eps=1e-3,\n",
    "                                        track_running_stats=False,\n",
    "                                        )\n",
    "        # TODO: Remove affine and use AddBias\n",
    "        # self.bias = AddBias(output_size)\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        maml_fc_init_(self.linear)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        # x = self.bias(x)\n",
    "        x = self.normalize(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class MAMLFC(nn.Sequential):\n",
    "\n",
    "    def __init__(self, input_size, output_size, sizes=None):\n",
    "        if sizes is None:\n",
    "            sizes = [256, 128, 64, 64]\n",
    "        layers = [MAMLLinearBlock(input_size, sizes[0]), ]\n",
    "        for s_i, s_o in zip(sizes[:-1], sizes[1:]):\n",
    "            layers.append(MAMLLinearBlock(s_i, s_o))\n",
    "        layers.append(maml_fc_init_(nn.Linear(sizes[-1], output_size)))\n",
    "        super(MAMLFC, self).__init__(*layers)\n",
    "#        super(MAMLFC, self).__init__(\n",
    "#            MAMLLinearBlock(input_size, 256),\n",
    "#            MAMLLinearBlock(256, 128),\n",
    "#            MAMLLinearBlock(128, 64),\n",
    "#            MAMLLinearBlock(64, 64),\n",
    "#            maml_fc_init_(nn.Linear(64, output_size)),\n",
    "#        )\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super(MAMLFC, self).forward(x.view(-1, self.input_size))\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "\n",
    "def fast_adapt(adaptation_data, evaluation_data, learner, loss, adaptation_steps, device):\n",
    "    for step in range(adaptation_steps):\n",
    "        data = [d for d in adaptation_data]\n",
    "        X = th.cat([d[0] for d in data], dim=0).to(device)\n",
    "        y = th.cat([th.tensor(d[1]).view(-1) for d in data], dim=0).to(device)\n",
    "        train_error = loss(learner(X), y)\n",
    "        train_error /= len(adaptation_data)\n",
    "        learner.adapt(train_error)\n",
    "    data = [d for d in evaluation_data]\n",
    "    X = th.cat([d[0] for d in data], dim=0).to(device)\n",
    "    y = th.cat([th.tensor(d[1]).view(-1) for d in data], dim=0).to(device)\n",
    "    predictions = learner(X)\n",
    "    valid_error = loss(predictions, y)\n",
    "    valid_error /= len(evaluation_data)\n",
    "    valid_accuracy = accuracy(predictions, y)\n",
    "    return valid_error, valid_accuracy\n",
    "\n",
    "\n",
    "\n",
    "def main(\n",
    "        ways=5,\n",
    "        shots=1,\n",
    "        meta_lr=0.003,\n",
    "        fast_lr=0.5,\n",
    "        meta_batch_size=32,\n",
    "        adaptation_steps=1,\n",
    "        num_iterations=60000,\n",
    "        cuda=True,\n",
    "        seed=42,\n",
    "    ):\n",
    "    from PIL.Image import LANCZOS\n",
    "    from torchvision.datasets import Omniglot\n",
    "    from torchvision import transforms\n",
    "    from torch.utils.data import ConcatDataset\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    th.manual_seed(seed)\n",
    "    device = th.device('cpu')\n",
    "    if cuda:\n",
    "        th.cuda.manual_seed(seed)\n",
    "        device = th.device('cuda')\n",
    "\n",
    "    # Create Dataset\n",
    "    # TODO: Create l2l.data.vision.FullOmniglot, which merges background and evaluation sets.\n",
    "    omni_background = Omniglot(root='./data',\n",
    "                               background=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   # TODO: Add DiscreteRotations([0, 90, 180, 270])\n",
    "                                   lambda x: 1.0 - x,\n",
    "                               ]),\n",
    "                               download=True)\n",
    "#    max_y = 1 + max([y for X, y in omni_background])\n",
    "    max_y = 964\n",
    "    omni_evaluation = Omniglot(root='./data',\n",
    "                               background=False,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   # TODO: Add DiscreteRotations([0, 90, 180, 270])\n",
    "                                   lambda x: 1.0 - x,\n",
    "                               ]),\n",
    "                               target_transform=transforms.Compose([\n",
    "                                   lambda x: max_y + x,\n",
    "                               ]),\n",
    "                               download=True)\n",
    "    omniglot = ConcatDataset((omni_background, omni_evaluation))\n",
    "    train_generator = l2l.data.TaskGenerator(dataset=omniglot, ways=ways)\n",
    "    valid_generator = l2l.data.TaskGenerator(dataset=omniglot, ways=ways)\n",
    "    test_generator = l2l.data.TaskGenerator(dataset=omniglot, ways=ways)\n",
    "    # TODO: Implement an easy way to split one dataset into splits, based on classes.\n",
    "\n",
    "    # Create model\n",
    "    model = MAMLFC(28**2, ways)\n",
    "    model.to(device)\n",
    "    maml = MAML(model, lr=fast_lr, first_order=False)\n",
    "    opt = optim.Adam(maml.parameters(), meta_lr)\n",
    "    loss = nn.CrossEntropyLoss(size_average=True, reduction='mean')\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        opt.zero_grad()\n",
    "        meta_train_error = 0.0\n",
    "        meta_train_accuracy = 0.0\n",
    "        meta_valid_error = 0.0\n",
    "        meta_valid_accuracy = 0.0\n",
    "        meta_test_error = 0.0\n",
    "        meta_test_accuracy = 0.0\n",
    "        for task in range(meta_batch_size):\n",
    "            # Compute meta-training loss\n",
    "            learner = maml.clone()\n",
    "            adaptation_data = train_generator.sample(shots=shots)\n",
    "            evaluation_data = train_generator.sample(shots=shots,\n",
    "                                                     classes_to_sample=adaptation_data.sampled_classes)\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(adaptation_data,\n",
    "                                                               evaluation_data,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               device)\n",
    "            evaluation_error.backward()\n",
    "            meta_train_error += evaluation_error.item()\n",
    "            meta_train_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "            # Compute meta-validation loss\n",
    "            learner = maml.clone()\n",
    "            adaptation_data = valid_generator.sample(shots=shots)\n",
    "            evaluation_data = valid_generator.sample(shots=shots,\n",
    "                                                     classes_to_sample=adaptation_data.sampled_classes)\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(adaptation_data,\n",
    "                                                               evaluation_data,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               device)\n",
    "            meta_valid_error += evaluation_error.item()\n",
    "            meta_valid_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "            # Compute meta-testing loss\n",
    "            learner = maml.clone()\n",
    "            adaptation_data = test_generator.sample(shots=shots)\n",
    "            evaluation_data = test_generator.sample(shots=shots,\n",
    "                                                    classes_to_sample=adaptation_data.sampled_classes)\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(adaptation_data,\n",
    "                                                               evaluation_data,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               device)\n",
    "            meta_test_error += evaluation_error.item()\n",
    "            meta_test_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "        # Print some metrics\n",
    "        print('\\n')\n",
    "        print('Iteration', iteration)\n",
    "        print('Meta Train Error', meta_train_error / meta_batch_size)\n",
    "        print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
    "        print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
    "        print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
    "        print('Meta Test Error', meta_test_error / meta_batch_size)\n",
    "        print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
    "\n",
    "        # Average the accumulated gradients and optimize\n",
    "        for p in maml.parameters():\n",
    "            p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "        opt.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/fewshot/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iteration 0\n",
      "Meta Train Error 0.31229730788618326\n",
      "Meta Train Accuracy 0.44375001126900315\n",
      "Meta Valid Error 0.31193888559937477\n",
      "Meta Valid Accuracy 0.41875001043081284\n",
      "Meta Test Error 0.3159230723977089\n",
      "Meta Test Accuracy 0.33750000689178705\n",
      "\n",
      "\n",
      "Iteration 1\n",
      "Meta Train Error 0.3043672563508153\n",
      "Meta Train Accuracy 0.48125001322478056\n",
      "Meta Valid Error 0.30012034717947245\n",
      "Meta Valid Accuracy 0.5937500135041773\n",
      "Meta Test Error 0.2989203268662095\n",
      "Meta Test Accuracy 0.5562500152736902\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "Meta Train Error 0.2911027930676937\n",
      "Meta Train Accuracy 0.5625000116415322\n",
      "Meta Valid Error 0.2865180401131511\n",
      "Meta Valid Accuracy 0.568750015925616\n",
      "Meta Test Error 0.2849751953035593\n",
      "Meta Test Accuracy 0.5875000138767064\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "Meta Train Error 0.27604627050459385\n",
      "Meta Train Accuracy 0.637500012293458\n",
      "Meta Valid Error 0.28138114139437675\n",
      "Meta Valid Accuracy 0.6187500120140612\n",
      "Meta Test Error 0.28452222887426615\n",
      "Meta Test Accuracy 0.5562500110827386\n",
      "\n",
      "\n",
      "Iteration 4\n",
      "Meta Train Error 0.27506551891565323\n",
      "Meta Train Accuracy 0.5250000124797225\n",
      "Meta Valid Error 0.26760421600192785\n",
      "Meta Valid Accuracy 0.5937500135041773\n",
      "Meta Test Error 0.26629060599952936\n",
      "Meta Test Accuracy 0.6187500129453838\n",
      "\n",
      "\n",
      "Iteration 5\n",
      "Meta Train Error 0.2750835786573589\n",
      "Meta Train Accuracy 0.5125000136904418\n",
      "Meta Valid Error 0.26828065840527415\n",
      "Meta Valid Accuracy 0.5500000123865902\n",
      "Meta Test Error 0.26621884666383266\n",
      "Meta Test Accuracy 0.6625000122003257\n",
      "\n",
      "\n",
      "Iteration 6\n",
      "Meta Train Error 0.2577144782990217\n",
      "Meta Train Accuracy 0.5875000143423676\n",
      "Meta Valid Error 0.2605376895517111\n",
      "Meta Valid Accuracy 0.568750012665987\n",
      "Meta Test Error 0.263044482562691\n",
      "Meta Test Accuracy 0.5750000146217644\n",
      "\n",
      "\n",
      "Iteration 7\n",
      "Meta Train Error 0.25924138398841023\n",
      "Meta Train Accuracy 0.5687500135973096\n",
      "Meta Valid Error 0.27582578593865037\n",
      "Meta Valid Accuracy 0.4937500124797225\n",
      "Meta Test Error 0.2696172734722495\n",
      "Meta Test Accuracy 0.5562500134110451\n",
      "\n",
      "\n",
      "Iteration 8\n",
      "Meta Train Error 0.2652540155686438\n",
      "Meta Train Accuracy 0.537500012665987\n",
      "Meta Valid Error 0.26647895807400346\n",
      "Meta Valid Accuracy 0.5250000138767064\n",
      "Meta Test Error 0.2669313787482679\n",
      "Meta Test Accuracy 0.5562500152736902\n",
      "\n",
      "\n",
      "Iteration 9\n",
      "Meta Train Error 0.24746269034221768\n",
      "Meta Train Accuracy 0.6312500117346644\n",
      "Meta Valid Error 0.2521656770259142\n",
      "Meta Valid Accuracy 0.6250000121071935\n",
      "Meta Test Error 0.26925129257142544\n",
      "Meta Test Accuracy 0.512500012293458\n",
      "\n",
      "\n",
      "Iteration 10\n",
      "Meta Train Error 0.25207725958898664\n",
      "Meta Train Accuracy 0.5562500152736902\n",
      "Meta Valid Error 0.25506794173270464\n",
      "Meta Valid Accuracy 0.5812500133179128\n",
      "Meta Test Error 0.2521797805093229\n",
      "Meta Test Accuracy 0.5687500135973096\n",
      "\n",
      "\n",
      "Iteration 11\n",
      "Meta Train Error 0.25119488313794136\n",
      "Meta Train Accuracy 0.5750000132247806\n",
      "Meta Valid Error 0.24000640073791146\n",
      "Meta Valid Accuracy 0.6500000129453838\n",
      "Meta Test Error 0.246205338742584\n",
      "Meta Test Accuracy 0.606250015553087\n",
      "\n",
      "\n",
      "Iteration 12\n",
      "Meta Train Error 0.24571525119245052\n",
      "Meta Train Accuracy 0.5812500147148967\n",
      "Meta Valid Error 0.24864769773557782\n",
      "Meta Valid Accuracy 0.5750000132247806\n",
      "Meta Test Error 0.25665987422689795\n",
      "Meta Test Accuracy 0.5687500122003257\n",
      "\n",
      "\n",
      "Iteration 13\n",
      "Meta Train Error 0.2325711650773883\n",
      "Meta Train Accuracy 0.6187500143423676\n",
      "Meta Valid Error 0.2424303973093629\n",
      "Meta Valid Accuracy 0.6125000109896064\n",
      "Meta Test Error 0.23061465378850698\n",
      "Meta Test Accuracy 0.6125000109896064\n",
      "\n",
      "\n",
      "Iteration 14\n",
      "Meta Train Error 0.23238373873755336\n",
      "Meta Train Accuracy 0.6812500120140612\n",
      "Meta Valid Error 0.2463014987297356\n",
      "Meta Valid Accuracy 0.5687500131316483\n",
      "Meta Test Error 0.2489752327091992\n",
      "Meta Test Accuracy 0.5812500137835741\n",
      "\n",
      "\n",
      "Iteration 15\n",
      "Meta Train Error 0.2315171924419701\n",
      "Meta Train Accuracy 0.6187500129453838\n",
      "Meta Valid Error 0.2382333455607295\n",
      "Meta Valid Accuracy 0.600000015925616\n",
      "Meta Test Error 0.24332491448149085\n",
      "Meta Test Accuracy 0.5312500111758709\n",
      "\n",
      "\n",
      "Iteration 16\n",
      "Meta Train Error 0.2355978819541633\n",
      "Meta Train Accuracy 0.5937500116415322\n",
      "Meta Valid Error 0.23370514437556267\n",
      "Meta Valid Accuracy 0.5875000134110451\n",
      "Meta Test Error 0.21924221701920033\n",
      "Meta Test Accuracy 0.6625000140629709\n",
      "\n",
      "\n",
      "Iteration 17\n",
      "Meta Train Error 0.23512208135798573\n",
      "Meta Train Accuracy 0.5625000121071935\n",
      "Meta Valid Error 0.2387702795676887\n",
      "Meta Valid Accuracy 0.6187500129453838\n",
      "Meta Test Error 0.23986989399418235\n",
      "Meta Test Accuracy 0.5937500125728548\n",
      "\n",
      "\n",
      "Iteration 18\n",
      "Meta Train Error 0.21812889445573092\n",
      "Meta Train Accuracy 0.6437500128522515\n",
      "Meta Valid Error 0.23759552463889122\n",
      "Meta Valid Accuracy 0.5875000129453838\n",
      "Meta Test Error 0.23562653129920363\n",
      "Meta Test Accuracy 0.5875000129453838\n",
      "\n",
      "\n",
      "Iteration 19\n",
      "Meta Train Error 0.22454737592488527\n",
      "Meta Train Accuracy 0.6312500112690032\n",
      "Meta Valid Error 0.22976265475153923\n",
      "Meta Valid Accuracy 0.6125000128522515\n",
      "Meta Test Error 0.2051409208215773\n",
      "Meta Test Accuracy 0.7500000107102096\n",
      "\n",
      "\n",
      "Iteration 20\n",
      "Meta Train Error 0.20994632365182042\n",
      "Meta Train Accuracy 0.6375000141561031\n",
      "Meta Valid Error 0.22722464427351952\n",
      "Meta Valid Accuracy 0.593750013038516\n",
      "Meta Test Error 0.22843741392716765\n",
      "Meta Test Accuracy 0.6375000113621354\n",
      "\n",
      "\n",
      "Iteration 21\n",
      "Meta Train Error 0.21309131104499102\n",
      "Meta Train Accuracy 0.6562500135041773\n",
      "Meta Valid Error 0.19837476569227874\n",
      "Meta Valid Accuracy 0.7375000128522515\n",
      "Meta Test Error 0.2123498609289527\n",
      "Meta Test Accuracy 0.6562500125728548\n",
      "\n",
      "\n",
      "Iteration 22\n",
      "Meta Train Error 0.2031428252812475\n",
      "Meta Train Accuracy 0.7062500123865902\n",
      "Meta Valid Error 0.1902628978714347\n",
      "Meta Valid Accuracy 0.7375000114552677\n",
      "Meta Test Error 0.2019979259930551\n",
      "Meta Test Accuracy 0.656250013038516\n",
      "\n",
      "\n",
      "Iteration 23\n",
      "Meta Train Error 0.1952958470210433\n",
      "Meta Train Accuracy 0.6750000114552677\n",
      "Meta Valid Error 0.20884779561311007\n",
      "Meta Valid Accuracy 0.6250000125728548\n",
      "Meta Test Error 0.21143288328312337\n",
      "Meta Test Accuracy 0.6500000124797225\n",
      "\n",
      "\n",
      "Iteration 24\n",
      "Meta Train Error 0.22473599738441408\n",
      "Meta Train Accuracy 0.6187500101514161\n",
      "Meta Valid Error 0.19388100528158247\n",
      "Meta Valid Accuracy 0.7187500111758709\n",
      "Meta Test Error 0.20961364405229688\n",
      "Meta Test Accuracy 0.6812500092200935\n",
      "\n",
      "\n",
      "Iteration 25\n",
      "Meta Train Error 0.21452294010668993\n",
      "Meta Train Accuracy 0.606250012293458\n",
      "Meta Valid Error 0.18731930037029088\n",
      "Meta Valid Accuracy 0.7500000093132257\n",
      "Meta Test Error 0.20261408342048526\n",
      "Meta Test Accuracy 0.6625000122003257\n",
      "\n",
      "\n",
      "Iteration 26\n",
      "Meta Train Error 0.1949892456177622\n",
      "Meta Train Accuracy 0.718750009778887\n",
      "Meta Valid Error 0.17511280300095677\n",
      "Meta Valid Accuracy 0.7312500113621354\n",
      "Meta Test Error 0.21168772783130407\n",
      "Meta Test Accuracy 0.600000012665987\n",
      "\n",
      "\n",
      "Iteration 27\n",
      "Meta Train Error 0.2023032302968204\n",
      "Meta Train Accuracy 0.6500000129453838\n",
      "Meta Valid Error 0.19518105895258486\n",
      "Meta Valid Accuracy 0.7187500088475645\n",
      "Meta Test Error 0.19528745720162988\n",
      "Meta Test Accuracy 0.6937500135973096\n",
      "\n",
      "\n",
      "Iteration 28\n",
      "Meta Train Error 0.17583063733763993\n",
      "Meta Train Accuracy 0.7250000089406967\n",
      "Meta Valid Error 0.20524671021848917\n",
      "Meta Valid Accuracy 0.6375000108964741\n",
      "Meta Test Error 0.1926808978896588\n",
      "Meta Test Accuracy 0.6687500099651515\n",
      "\n",
      "\n",
      "Iteration 29\n",
      "Meta Train Error 0.20190486637875438\n",
      "Meta Train Accuracy 0.6500000101514161\n",
      "Meta Valid Error 0.20904886513017118\n",
      "Meta Valid Accuracy 0.5750000127591193\n",
      "Meta Test Error 0.20413172943517566\n",
      "Meta Test Accuracy 0.6437500128522515\n",
      "\n",
      "\n",
      "Iteration 30\n",
      "Meta Train Error 0.17166990344412625\n",
      "Meta Train Accuracy 0.718750009778887\n",
      "Meta Valid Error 0.1996282695326954\n",
      "Meta Valid Accuracy 0.6375000118277967\n",
      "Meta Test Error 0.16129724378697574\n",
      "Meta Test Accuracy 0.7500000107102096\n",
      "\n",
      "\n",
      "Iteration 31\n",
      "Meta Train Error 0.17370218457654119\n",
      "Meta Train Accuracy 0.7250000122003257\n",
      "Meta Valid Error 0.1781594193307683\n",
      "Meta Valid Accuracy 0.7375000109896064\n",
      "Meta Test Error 0.18666230514645576\n",
      "Meta Test Accuracy 0.7000000132247806\n",
      "\n",
      "\n",
      "Iteration 32\n",
      "Meta Train Error 0.18391517270356417\n",
      "Meta Train Accuracy 0.6937500135973096\n",
      "Meta Valid Error 0.15167622070293874\n",
      "Meta Valid Accuracy 0.7687500095926225\n",
      "Meta Test Error 0.18320438521914184\n",
      "Meta Test Accuracy 0.7000000132247806\n",
      "\n",
      "\n",
      "Iteration 33\n",
      "Meta Train Error 0.1850253778975457\n",
      "Meta Train Accuracy 0.7062500142492354\n",
      "Meta Valid Error 0.16855541989207268\n",
      "Meta Valid Accuracy 0.7187500111758709\n",
      "Meta Test Error 0.1745229782536626\n",
      "Meta Test Accuracy 0.7562500117346644\n",
      "\n",
      "\n",
      "Iteration 34\n",
      "Meta Train Error 0.19046191161032766\n",
      "Meta Train Accuracy 0.6562500116415322\n",
      "Meta Valid Error 0.2043282554950565\n",
      "Meta Valid Accuracy 0.6500000115483999\n",
      "Meta Test Error 0.19946888787671924\n",
      "Meta Test Accuracy 0.6562500135041773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iteration 35\n",
      "Meta Train Error 0.16446618421468884\n",
      "Meta Train Accuracy 0.7312500108964741\n",
      "Meta Valid Error 0.1774138929322362\n",
      "Meta Valid Accuracy 0.6937500140629709\n",
      "Meta Test Error 0.2030633909162134\n",
      "Meta Test Accuracy 0.5812500128522515\n",
      "\n",
      "\n",
      "Iteration 36\n",
      "Meta Train Error 0.16824059654027224\n",
      "Meta Train Accuracy 0.7125000115483999\n",
      "Meta Valid Error 0.1805078205652535\n",
      "Meta Valid Accuracy 0.7187500121071935\n",
      "Meta Test Error 0.1669217178132385\n",
      "Meta Test Accuracy 0.731250009033829\n",
      "\n",
      "\n",
      "Iteration 37\n",
      "Meta Train Error 0.16904267820063978\n",
      "Meta Train Accuracy 0.7125000110827386\n",
      "Meta Valid Error 0.19665839697699994\n",
      "Meta Valid Accuracy 0.6812500110827386\n",
      "Meta Test Error 0.16468996845651418\n",
      "Meta Test Accuracy 0.7187500149011612\n",
      "\n",
      "\n",
      "Iteration 38\n",
      "Meta Train Error 0.17568306589964777\n",
      "Meta Train Accuracy 0.7000000118277967\n",
      "Meta Valid Error 0.18122114962898195\n",
      "Meta Valid Accuracy 0.6875000107102096\n",
      "Meta Test Error 0.19467550492845476\n",
      "Meta Test Accuracy 0.6625000098720193\n",
      "\n",
      "\n",
      "Iteration 39\n",
      "Meta Train Error 0.16886910167522728\n",
      "Meta Train Accuracy 0.7500000121071935\n",
      "Meta Valid Error 0.16837007633876055\n",
      "Meta Valid Accuracy 0.7437500101514161\n",
      "Meta Test Error 0.16863012197427452\n",
      "Meta Test Accuracy 0.6937500122003257\n",
      "\n",
      "\n",
      "Iteration 40\n",
      "Meta Train Error 0.16147391125559807\n",
      "Meta Train Accuracy 0.7437500092200935\n",
      "Meta Valid Error 0.17201393912546337\n",
      "Meta Valid Accuracy 0.6937500103376806\n",
      "Meta Test Error 0.17450521199498326\n",
      "Meta Test Accuracy 0.7000000094994903\n",
      "\n",
      "\n",
      "Iteration 41\n",
      "Meta Train Error 0.15307398489676416\n",
      "Meta Train Accuracy 0.793750009033829\n",
      "Meta Valid Error 0.16601104696746916\n",
      "Meta Valid Accuracy 0.7312500099651515\n",
      "Meta Test Error 0.14124056417495012\n",
      "Meta Test Accuracy 0.7750000110827386\n",
      "\n",
      "\n",
      "Iteration 42\n",
      "Meta Train Error 0.1762228428851813\n",
      "Meta Train Accuracy 0.7062500123865902\n",
      "Meta Valid Error 0.1952077066525817\n",
      "Meta Valid Accuracy 0.6187500096857548\n",
      "Meta Test Error 0.1872449368238449\n",
      "Meta Test Accuracy 0.6812500101514161\n",
      "\n",
      "\n",
      "Iteration 43\n",
      "Meta Train Error 0.17807197221554816\n",
      "Meta Train Accuracy 0.6625000117346644\n",
      "Meta Valid Error 0.19250642112456262\n",
      "Meta Valid Accuracy 0.6500000087544322\n",
      "Meta Test Error 0.15466251352336258\n",
      "Meta Test Accuracy 0.725000012665987\n",
      "\n",
      "\n",
      "Iteration 44\n",
      "Meta Train Error 0.18330751464236528\n",
      "Meta Train Accuracy 0.7250000122003257\n",
      "Meta Valid Error 0.17173126665875316\n",
      "Meta Valid Accuracy 0.6937500122003257\n",
      "Meta Test Error 0.15625802450813353\n",
      "Meta Test Accuracy 0.7250000080093741\n",
      "\n",
      "\n",
      "Iteration 45\n",
      "Meta Train Error 0.17691535910125822\n",
      "Meta Train Accuracy 0.7000000104308128\n",
      "Meta Valid Error 0.15768481488339603\n",
      "Meta Valid Accuracy 0.7187500083819032\n",
      "Meta Test Error 0.1551266685128212\n",
      "Meta Test Accuracy 0.7500000116415322\n",
      "\n",
      "\n",
      "Iteration 46\n",
      "Meta Train Error 0.20682628103531897\n",
      "Meta Train Accuracy 0.6312500112690032\n",
      "Meta Valid Error 0.14055598806589842\n",
      "Meta Valid Accuracy 0.7625000099651515\n",
      "Meta Test Error 0.1747729696216993\n",
      "Meta Test Accuracy 0.7187500088475645\n",
      "\n",
      "\n",
      "Iteration 47\n",
      "Meta Train Error 0.15384386444929987\n",
      "Meta Train Accuracy 0.7062500105239451\n",
      "Meta Valid Error 0.16463933151680976\n",
      "Meta Valid Accuracy 0.7437500101514161\n",
      "Meta Test Error 0.19986291625536978\n",
      "Meta Test Accuracy 0.6437500086612999\n",
      "\n",
      "\n",
      "Iteration 48\n",
      "Meta Train Error 0.13020000723190606\n",
      "Meta Train Accuracy 0.8312500077299774\n",
      "Meta Valid Error 0.1536175983492285\n",
      "Meta Valid Accuracy 0.7187500088475645\n",
      "Meta Test Error 0.1305751360487193\n",
      "Meta Test Accuracy 0.8250000094994903\n",
      "\n",
      "\n",
      "Iteration 49\n",
      "Meta Train Error 0.17645669810008258\n",
      "Meta Train Accuracy 0.6687500141561031\n",
      "Meta Valid Error 0.15150393859948963\n",
      "Meta Valid Accuracy 0.7562500117346644\n",
      "Meta Test Error 0.14627245825249702\n",
      "Meta Test Accuracy 0.7625000104308128\n",
      "\n",
      "\n",
      "Iteration 50\n",
      "Meta Train Error 0.18431173544377089\n",
      "Meta Train Accuracy 0.6687500104308128\n",
      "Meta Valid Error 0.14414207136724144\n",
      "Meta Valid Accuracy 0.7687500077299774\n",
      "Meta Test Error 0.16106764995492995\n",
      "Meta Test Accuracy 0.7375000077299774\n",
      "\n",
      "\n",
      "Iteration 51\n",
      "Meta Train Error 0.19732977799139917\n",
      "Meta Train Accuracy 0.6562500121071935\n",
      "Meta Valid Error 0.1627193004824221\n",
      "Meta Valid Accuracy 0.7125000115483999\n",
      "Meta Test Error 0.1554429258685559\n",
      "Meta Test Accuracy 0.7187500102445483\n",
      "\n",
      "\n",
      "Iteration 52\n",
      "Meta Train Error 0.15628039359580725\n",
      "Meta Train Accuracy 0.6750000114552677\n",
      "Meta Valid Error 0.15324742498341948\n",
      "Meta Valid Accuracy 0.7125000120140612\n",
      "Meta Test Error 0.15139775269199163\n",
      "Meta Test Accuracy 0.7687500091269612\n",
      "\n",
      "\n",
      "Iteration 53\n",
      "Meta Train Error 0.15170713106635958\n",
      "Meta Train Accuracy 0.7437500101514161\n",
      "Meta Valid Error 0.12711337569635361\n",
      "Meta Valid Accuracy 0.8187500066123903\n",
      "Meta Test Error 0.1354749392485246\n",
      "Meta Test Accuracy 0.7875000075437129\n",
      "\n",
      "\n",
      "Iteration 54\n",
      "Meta Train Error 0.16573321784380823\n",
      "Meta Train Accuracy 0.7187500074505806\n",
      "Meta Valid Error 0.18871572404168546\n",
      "Meta Valid Accuracy 0.6937500112690032\n",
      "Meta Test Error 0.1797107207821682\n",
      "Meta Test Accuracy 0.6812500129453838\n",
      "\n",
      "\n",
      "Iteration 55\n",
      "Meta Train Error 0.15420981659553945\n",
      "Meta Train Accuracy 0.7812500074505806\n",
      "Meta Valid Error 0.13123788754455745\n",
      "Meta Valid Accuracy 0.762500012293458\n",
      "Meta Test Error 0.15732080396264791\n",
      "Meta Test Accuracy 0.7125000101514161\n",
      "\n",
      "\n",
      "Iteration 56\n",
      "Meta Train Error 0.15512909193057567\n",
      "Meta Train Accuracy 0.7250000098720193\n",
      "Meta Valid Error 0.18226574076106772\n",
      "Meta Valid Accuracy 0.6437500137835741\n",
      "Meta Test Error 0.17312800494255498\n",
      "Meta Test Accuracy 0.6875000093132257\n",
      "\n",
      "\n",
      "Iteration 57\n",
      "Meta Train Error 0.16613899206276983\n",
      "Meta Train Accuracy 0.7062500114552677\n",
      "Meta Valid Error 0.15693935030139983\n",
      "Meta Valid Accuracy 0.7625000099651515\n",
      "Meta Test Error 0.16095987928565592\n",
      "Meta Test Accuracy 0.7125000115483999\n",
      "\n",
      "\n",
      "Iteration 58\n",
      "Meta Train Error 0.16032492252998054\n",
      "Meta Train Accuracy 0.7437500101514161\n",
      "Meta Valid Error 0.20078580011613667\n",
      "Meta Valid Accuracy 0.643750011920929\n",
      "Meta Test Error 0.15904094639699906\n",
      "Meta Test Accuracy 0.6875000093132257\n",
      "\n",
      "\n",
      "Iteration 59\n",
      "Meta Train Error 0.15630626096390188\n",
      "Meta Train Accuracy 0.737500011920929\n",
      "Meta Valid Error 0.14155317877884954\n",
      "Meta Valid Accuracy 0.7812500079162419\n",
      "Meta Test Error 0.1589686213992536\n",
      "Meta Test Accuracy 0.7500000111758709\n",
      "\n",
      "\n",
      "Iteration 60\n",
      "Meta Train Error 0.1509125581360422\n",
      "Meta Train Accuracy 0.737500011920929\n",
      "Meta Valid Error 0.20245494844857603\n",
      "Meta Valid Accuracy 0.6375000104308128\n",
      "Meta Test Error 0.16467020474374294\n",
      "Meta Test Accuracy 0.762500012293458\n",
      "\n",
      "\n",
      "Iteration 61\n",
      "Meta Train Error 0.17225726949982345\n",
      "Meta Train Accuracy 0.7125000092200935\n",
      "Meta Valid Error 0.13005206384696066\n",
      "Meta Valid Accuracy 0.8312500067986548\n",
      "Meta Test Error 0.13787695218343288\n",
      "Meta Test Accuracy 0.7625000104308128\n",
      "\n",
      "\n",
      "Iteration 62\n",
      "Meta Train Error 0.14826081355568022\n",
      "Meta Train Accuracy 0.7312500094994903\n",
      "Meta Valid Error 0.15729543601628393\n",
      "Meta Valid Accuracy 0.7187500079162419\n",
      "Meta Test Error 0.21825702325440943\n",
      "Meta Test Accuracy 0.6375000113621354\n",
      "\n",
      "\n",
      "Iteration 63\n",
      "Meta Train Error 0.19825799181126058\n",
      "Meta Train Accuracy 0.6500000115483999\n",
      "Meta Valid Error 0.19213062530616298\n",
      "Meta Valid Accuracy 0.643750011920929\n",
      "Meta Test Error 0.1731107064988464\n",
      "Meta Test Accuracy 0.7062500114552677\n",
      "\n",
      "\n",
      "Iteration 64\n",
      "Meta Train Error 0.15165181166958064\n",
      "Meta Train Accuracy 0.7500000079162419\n",
      "Meta Valid Error 0.16157320758793503\n",
      "Meta Valid Accuracy 0.6937500117346644\n",
      "Meta Test Error 0.15136671077925712\n",
      "Meta Test Accuracy 0.7437500110827386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-ff2e2adaf60d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ways, shots, meta_lr, fast_lr, meta_batch_size, adaptation_steps, num_iterations, cuda, seed)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m# Compute meta-validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0madaptation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             evaluation_data = valid_generator.sample(shots=shots,\n",
      "\u001b[0;32m<ipython-input-33-48cf8650d468>\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self, first_order)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst_order\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mfirst_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         return MAML(clone_module(self.module),\n\u001b[0m\u001b[1;32m     67\u001b[0m                     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     first_order=first_order)\n",
      "\u001b[0;32m/data/home/debo/learn2learn/learn2learn/utils.py\u001b[0m in \u001b[0;36mclone_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# First, re-write all parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/fewshot/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/fewshot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_state_dict_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "36_fewshot",
   "language": "python",
   "name": "fewshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
