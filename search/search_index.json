{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"learn2learn is a PyTorch library for meta-learning implementations. The goal of meta-learning is to enable agents to learn how to learn . That is, we would like our agents to become better learners over time such that learning to solve the 1000th task should happen faster when learning the 1st task. For example, once an agent has learned how to move north and south, we expect it to quickly pick up how to move east and west. Features learn2learn provides high- and low-level utilities for meta-learning. The high-level utilities allow arbitrary users to take advantage of exisiting meta-learning algorithms. The low-level utilities enable researchers to develop new and better meta-learning algorithms. Some features of learn2learn include: Modular API: implement your own training loops with our low-level utilities. Provides various meta-learning algorithms (e.g. MAML, FOMAML, MetaSGD, ProtoNets, DiCE) Task generator with unified API, compatible with torchvision, torchtext, torchaudio, and cherry. Provides standardized meta-learning tasks for vision (Omniglot, mini-ImageNet), reinforcement learning (Particles, Mujoco), and even text (news classification). 100% compatible with PyTorch -- use your own modules, datasets, or libraries! Installation pip install learn2learn API Demo The following is an example of using the high-level MAML implementation on MNIST. For more algorithms and lower-level utilities, please refer to the documentation or the examples . import learn2learn as l2l mnist = torchvision.datasets.MNIST(root=\"/tmp/mnist\", train=True) mnist = l2l.data.MetaDataset(mnist) task_generator = l2l.data.TaskGenerator(mnist, ways=3, classes=[0, 1, 4, 6, 8, 9], tasks=10) model = Net() maml = l2l.algorithms.MAML(model, lr=1e-3, first_order=False) opt = optim.Adam(maml.parameters(), lr=4e-3) for iteration in range(num_iterations): learner = maml.clone() # Creates a clone of model adaptation_task = task_generator.sample(shots=1) # Fast adapt for step in range(adaptation_steps): error = compute_loss(adaptation_task) learner.adapt(error) # Compute evaluation loss evaluation_task = task_generator.sample(shots=1, task=adaptation_task.sampled_task) evaluation_error = compute_loss(evaluation_task) # Meta-update the model parameters opt.zero_grad() evaluation_error.backward() opt.step() Acknowledgements The RL environments are adapted from Tristan Deleu's implementations and from the ProMP repository . Both shared with permission, under the MIT License.","title":"Home"},{"location":"#installation","text":"pip install learn2learn","title":"Installation"},{"location":"#api-demo","text":"The following is an example of using the high-level MAML implementation on MNIST. For more algorithms and lower-level utilities, please refer to the documentation or the examples . import learn2learn as l2l mnist = torchvision.datasets.MNIST(root=\"/tmp/mnist\", train=True) mnist = l2l.data.MetaDataset(mnist) task_generator = l2l.data.TaskGenerator(mnist, ways=3, classes=[0, 1, 4, 6, 8, 9], tasks=10) model = Net() maml = l2l.algorithms.MAML(model, lr=1e-3, first_order=False) opt = optim.Adam(maml.parameters(), lr=4e-3) for iteration in range(num_iterations): learner = maml.clone() # Creates a clone of model adaptation_task = task_generator.sample(shots=1) # Fast adapt for step in range(adaptation_steps): error = compute_loss(adaptation_task) learner.adapt(error) # Compute evaluation loss evaluation_task = task_generator.sample(shots=1, task=adaptation_task.sampled_task) evaluation_error = compute_loss(evaluation_task) # Meta-update the model parameters opt.zero_grad() evaluation_error.backward() opt.step()","title":"API Demo"},{"location":"#acknowledgements","text":"The RL environments are adapted from Tristan Deleu's implementations and from the ProMP repository . Both shared with permission, under the MIT License.","title":"Acknowledgements"},{"location":"docs/learn2learn.algorithms/","text":"MAML MAML(self, model, lr, first_order=False) [Source] Description High-level implementation of Model-Agnostic Meta-Learning . This class wraps an arbitrary nn.Module and augments it with clone() and adapt methods. For the first-order version of MAML (i.e. FOMAML), set the first_order flag to True upon initialization. Arguments model (Module) - Module to be wrapped. lr (float) - Fast adaptation learning rate. first_order (bool, optional , default=False) - Whether to use the References Finn et al. 2017. \u201cModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.\u201d Example linear = l2l.algorithms.MAML(nn.Linear(20, 10), lr=0.01) clone = linear.clone() error = loss(clone(X), y) clone.adapt(error) error = loss(clone(X), y) error.backward() adapt MAML.adapt(self, loss, first_order=None) Description Updates the clone parameters in place using the MAML update. Arguments loss (Tensor) - Loss to minimize upon update. first_order (bool, optional , default=None) - Whether to use first- or second-order updates. Defaults to self.first_order. clone MAML.clone(self, first_order=None) Description Returns a MAML -wrapped copy of the module whose parameters and buffers are torch.clone d from the original module. This implies that back-propagating losses on the cloned module will populate the buffers of the original module. For more information, refer to learn2learn.clone_module(). Arguments first_order (bool, optional , default=None) - Whether the clone uses first- or second-order updates. Defaults to self.first_order. maml_update maml_update(model, lr, grads=None) Description Performs a MAML update on model using grads and lr. The function re-routes the Python object, thus avoiding in-place operations. NOTE: The model itself is updated in-place (no deepcopy), but the parameters' tensors are not. Arguments model (Module) - The model to update. lr (float) - The learning rate used to update the model. grads (list, optional , default=None) - A list of gradients for each parameter of the model. If None, will use the gradients in .grad attributes. Example maml = l2l.algorithms.MAML(Model(), lr=0.1) model = maml.clone() # The next two lines essentially implement model.adapt(loss) grads = autograd.grad(loss, model.parameters(), create_graph=True) maml_update(model, lr=0.1, grads) MetaSGD MetaSGD(self, model, lr=1.0, first_order=False, lrs=None) [Source] Description High-level implementation of Meta-SGD . This class wraps an arbitrary nn.Module and augments it with clone() and adapt methods. It behaves similarly to MAML , but in addition a set of per-parameters learning rates are learned for fast-adaptation. Arguments model (Module) - Module to be wrapped. lr (float) - Initialization value of the per-parameter fast adaptation learning rates. first_order (bool, optional , default=False) - Whether to use the first-order version. lrs (list of Parameters, optional , default=None) - If not None, overrides lr , and uses the list as learning rates for fast-adaptation. References Li et al. 2017. \u201cMeta-SGD: Learning to Learn Quickly for Few-Shot Learning.\u201d arXiv. Example linear = l2l.algorithms.MetaSGD(nn.Linear(20, 10), lr=0.01) clone = linear.clone() error = loss(clone(X), y) clone.adapt(error) error = loss(clone(X), y) error.backward() clone MetaSGD.clone(self) Descritpion Akin to MAML.clone() but for MetaSGD: it includes a set of learnable fast-adaptation learning rates. adapt MetaSGD.adapt(self, loss, first_order=None) Descritpion Akin to MAML.adapt() but for MetaSGD: it updates the model with the learnable per-parameter learning rates. meta_sgd_update meta_sgd_update(model, lrs=None, grads=None) Description Performs a MetaSGD update on model using grads and lrs. The function re-routes the Python object, thus avoiding in-place operations. NOTE: The model itself is updated in-place (no deepcopy), but the parameters' tensors are not. Arguments model (Module) - The model to update. lrs (list) - The meta-learned learning rates used to update the model. grads (list, optional , default=None) - A list of gradients for each parameter of the model. If None, will use the gradients in .grad attributes. Example meta = l2l.algorithms.MetaSGD(Model(), lr=1.0) lrs = [th.ones_like(p) for p in meta.model.parameters()] model = meta.clone() # The next two lines essentially implement model.adapt(loss) grads = autograd.grad(loss, model.parameters(), create_graph=True) meta_sgd_update(model, lrs=lrs, grads)","title":"learn2learn.algorithms"},{"location":"docs/learn2learn.algorithms/#maml","text":"MAML(self, model, lr, first_order=False) [Source] Description High-level implementation of Model-Agnostic Meta-Learning . This class wraps an arbitrary nn.Module and augments it with clone() and adapt methods. For the first-order version of MAML (i.e. FOMAML), set the first_order flag to True upon initialization. Arguments model (Module) - Module to be wrapped. lr (float) - Fast adaptation learning rate. first_order (bool, optional , default=False) - Whether to use the References Finn et al. 2017. \u201cModel-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.\u201d Example linear = l2l.algorithms.MAML(nn.Linear(20, 10), lr=0.01) clone = linear.clone() error = loss(clone(X), y) clone.adapt(error) error = loss(clone(X), y) error.backward()","title":"MAML"},{"location":"docs/learn2learn.algorithms/#adapt","text":"MAML.adapt(self, loss, first_order=None) Description Updates the clone parameters in place using the MAML update. Arguments loss (Tensor) - Loss to minimize upon update. first_order (bool, optional , default=None) - Whether to use first- or second-order updates. Defaults to self.first_order.","title":"adapt"},{"location":"docs/learn2learn.algorithms/#clone","text":"MAML.clone(self, first_order=None) Description Returns a MAML -wrapped copy of the module whose parameters and buffers are torch.clone d from the original module. This implies that back-propagating losses on the cloned module will populate the buffers of the original module. For more information, refer to learn2learn.clone_module(). Arguments first_order (bool, optional , default=None) - Whether the clone uses first- or second-order updates. Defaults to self.first_order.","title":"clone"},{"location":"docs/learn2learn.algorithms/#maml_update","text":"maml_update(model, lr, grads=None) Description Performs a MAML update on model using grads and lr. The function re-routes the Python object, thus avoiding in-place operations. NOTE: The model itself is updated in-place (no deepcopy), but the parameters' tensors are not. Arguments model (Module) - The model to update. lr (float) - The learning rate used to update the model. grads (list, optional , default=None) - A list of gradients for each parameter of the model. If None, will use the gradients in .grad attributes. Example maml = l2l.algorithms.MAML(Model(), lr=0.1) model = maml.clone() # The next two lines essentially implement model.adapt(loss) grads = autograd.grad(loss, model.parameters(), create_graph=True) maml_update(model, lr=0.1, grads)","title":"maml_update"},{"location":"docs/learn2learn.algorithms/#metasgd","text":"MetaSGD(self, model, lr=1.0, first_order=False, lrs=None) [Source] Description High-level implementation of Meta-SGD . This class wraps an arbitrary nn.Module and augments it with clone() and adapt methods. It behaves similarly to MAML , but in addition a set of per-parameters learning rates are learned for fast-adaptation. Arguments model (Module) - Module to be wrapped. lr (float) - Initialization value of the per-parameter fast adaptation learning rates. first_order (bool, optional , default=False) - Whether to use the first-order version. lrs (list of Parameters, optional , default=None) - If not None, overrides lr , and uses the list as learning rates for fast-adaptation. References Li et al. 2017. \u201cMeta-SGD: Learning to Learn Quickly for Few-Shot Learning.\u201d arXiv. Example linear = l2l.algorithms.MetaSGD(nn.Linear(20, 10), lr=0.01) clone = linear.clone() error = loss(clone(X), y) clone.adapt(error) error = loss(clone(X), y) error.backward()","title":"MetaSGD"},{"location":"docs/learn2learn.algorithms/#clone_1","text":"MetaSGD.clone(self) Descritpion Akin to MAML.clone() but for MetaSGD: it includes a set of learnable fast-adaptation learning rates.","title":"clone"},{"location":"docs/learn2learn.algorithms/#adapt_1","text":"MetaSGD.adapt(self, loss, first_order=None) Descritpion Akin to MAML.adapt() but for MetaSGD: it updates the model with the learnable per-parameter learning rates.","title":"adapt"},{"location":"docs/learn2learn.algorithms/#meta_sgd_update","text":"meta_sgd_update(model, lrs=None, grads=None) Description Performs a MetaSGD update on model using grads and lrs. The function re-routes the Python object, thus avoiding in-place operations. NOTE: The model itself is updated in-place (no deepcopy), but the parameters' tensors are not. Arguments model (Module) - The model to update. lrs (list) - The meta-learned learning rates used to update the model. grads (list, optional , default=None) - A list of gradients for each parameter of the model. If None, will use the gradients in .grad attributes. Example meta = l2l.algorithms.MetaSGD(Model(), lr=1.0) lrs = [th.ones_like(p) for p in meta.model.parameters()] model = meta.clone() # The next two lines essentially implement model.adapt(loss) grads = autograd.grad(loss, model.parameters(), create_graph=True) meta_sgd_update(model, lrs=lrs, grads)","title":"meta_sgd_update"},{"location":"docs/learn2learn.data/","text":"MetaDataset MetaDataset(self, dataset) Descritpion It wraps a torch dataset by creating a map of target to indices. This comes in handy when we want to sample elements randomly for a particular label. Notes: For l2l to work its important that the dataset returns a (data, target) tuple. If your dataset doesn't return that, it should be trivial to wrap your dataset with another class to do that. TODO : Add example for wrapping a non standard l2l dataset Arguments dataset (Dataset) - A torch dataset. Example mnist = torchvision.datasets.MNIST(root=\"/tmp/mnist\", train=True) mnist = l2l.data.MetaDataset(mnist) TaskGenerator TaskGenerator(self, dataset, classes=None, ways=2, tasks=1, shots=1) [Source] Description A wrapper to generate few-shot classification tasks. tasks can both indicate predefined tasks, or just the number of tasks to sample. If specified as an int, a list of size task would be generated from which we'll sample. If specified as a list, then that list of tasks would be used to sample always. The acceptable shape of list would be n * w , with n the number of tasks to sample and w the number of ways. Each of the task should have w distinct elements all of which are required to be a subset of ways. Arguments dataset (MetaDataset or Dataset) - The (meta-) dataset to wrap. classes (list, optional , default=None) - List of classes to sample from, if none then sample from all available classes in dataset. (default: None) ways (int, optional , default=2) - Number of labels to sample from. shots (int, optional , default=1) - Number of data points per task to sample. tasks (int or list, optional , default=1) - Tasks to be generated. sample TaskGenerator.sample(self, shots=None, task=None) Description Returns a dataset and the labels that we have sampled. The dataset is of length shots * ways . The length of labels we have sampled is the same as shots . Arguments shots (int, optional , default=None) - Number of data points to return per class, if None gets self.shots. task (list, optional , default=None) - List of labels you want to sample from. Returns Dataset - Containing the sampled task.","title":"learn2learn.data"},{"location":"docs/learn2learn.data/#metadataset","text":"MetaDataset(self, dataset) Descritpion It wraps a torch dataset by creating a map of target to indices. This comes in handy when we want to sample elements randomly for a particular label. Notes: For l2l to work its important that the dataset returns a (data, target) tuple. If your dataset doesn't return that, it should be trivial to wrap your dataset with another class to do that. TODO : Add example for wrapping a non standard l2l dataset Arguments dataset (Dataset) - A torch dataset. Example mnist = torchvision.datasets.MNIST(root=\"/tmp/mnist\", train=True) mnist = l2l.data.MetaDataset(mnist)","title":"MetaDataset"},{"location":"docs/learn2learn.data/#taskgenerator","text":"TaskGenerator(self, dataset, classes=None, ways=2, tasks=1, shots=1) [Source] Description A wrapper to generate few-shot classification tasks. tasks can both indicate predefined tasks, or just the number of tasks to sample. If specified as an int, a list of size task would be generated from which we'll sample. If specified as a list, then that list of tasks would be used to sample always. The acceptable shape of list would be n * w , with n the number of tasks to sample and w the number of ways. Each of the task should have w distinct elements all of which are required to be a subset of ways. Arguments dataset (MetaDataset or Dataset) - The (meta-) dataset to wrap. classes (list, optional , default=None) - List of classes to sample from, if none then sample from all available classes in dataset. (default: None) ways (int, optional , default=2) - Number of labels to sample from. shots (int, optional , default=1) - Number of data points per task to sample. tasks (int or list, optional , default=1) - Tasks to be generated.","title":"TaskGenerator"},{"location":"docs/learn2learn.data/#sample","text":"TaskGenerator.sample(self, shots=None, task=None) Description Returns a dataset and the labels that we have sampled. The dataset is of length shots * ways . The length of labels we have sampled is the same as shots . Arguments shots (int, optional , default=None) - Number of data points to return per class, if None gets self.shots. task (list, optional , default=None) - List of labels you want to sample from. Returns Dataset - Containing the sampled task.","title":"sample"},{"location":"docs/learn2learn.gym/","text":"learn2learn.gym","title":"learn2learn.gym"},{"location":"docs/learn2learn.gym/#learn2learngym","text":"","title":"learn2learn.gym"},{"location":"docs/learn2learn/","text":"clone_module clone_module(module) [Source] Description Creates a copy of a module, whose parameters/buffers/submodules are created using PyTorch's torch.clone(). This implies that the computational graph is kept, and you can compute the derivatives of the new modules' parameters w.r.t the original parameters. Arguments module (Module) - Module to be cloned. Return (Module) - The cloned module. Example net = nn.Sequential(Linear(20, 10), nn.ReLU(), nn.Linear(10, 2)) clone = clone_module(net) error = loss(clone(X), y) error.backward() # Gradients are back-propagate all the way to net. detach_module detach_module(module) [Source] Description Detaches all parameters/buffers of a previously cloned module from its computational graph. Note: detach works in-place, so it does not return a copy. Arguments module (Module) - Module to be detached. Example net = nn.Sequential(Linear(20, 10), nn.ReLU(), nn.Linear(10, 2)) clone = clone_module(net) detach_module(clone) error = loss(clone(X), y) error.backward() # Gradients are back-propagate on clone, not net. magic_box magic_box(x) [Source] Description The magic box operator, which evaluates to 1 but whose gradient is dx : \\boxdot (x) = \\exp(x - \\bot(x)) where \\bot is the stop-gradient (or detach) operator. This operator is useful when computing higher-order derivatives of stochastic graphs. For more informations, please refer to the DiCE paper. (Reference 1) References Foerster et al. 2018. \u201cDiCE: The Infinitely Differentiable Monte-Carlo Estimator.\u201d arXiv. Arguments x (Variable) - Variable to transform. Return (Variable) - Tensor of 1, but it's gradient is the gradient of x. Example loss = (magic_box(cum_log_probs) * advantages).mean() # loss is the mean advantage loss.backward()","title":"learn2learn"},{"location":"docs/learn2learn/#clone_module","text":"clone_module(module) [Source] Description Creates a copy of a module, whose parameters/buffers/submodules are created using PyTorch's torch.clone(). This implies that the computational graph is kept, and you can compute the derivatives of the new modules' parameters w.r.t the original parameters. Arguments module (Module) - Module to be cloned. Return (Module) - The cloned module. Example net = nn.Sequential(Linear(20, 10), nn.ReLU(), nn.Linear(10, 2)) clone = clone_module(net) error = loss(clone(X), y) error.backward() # Gradients are back-propagate all the way to net.","title":"clone_module"},{"location":"docs/learn2learn/#detach_module","text":"detach_module(module) [Source] Description Detaches all parameters/buffers of a previously cloned module from its computational graph. Note: detach works in-place, so it does not return a copy. Arguments module (Module) - Module to be detached. Example net = nn.Sequential(Linear(20, 10), nn.ReLU(), nn.Linear(10, 2)) clone = clone_module(net) detach_module(clone) error = loss(clone(X), y) error.backward() # Gradients are back-propagate on clone, not net.","title":"detach_module"},{"location":"docs/learn2learn/#magic_box","text":"magic_box(x) [Source] Description The magic box operator, which evaluates to 1 but whose gradient is dx : \\boxdot (x) = \\exp(x - \\bot(x)) where \\bot is the stop-gradient (or detach) operator. This operator is useful when computing higher-order derivatives of stochastic graphs. For more informations, please refer to the DiCE paper. (Reference 1) References Foerster et al. 2018. \u201cDiCE: The Infinitely Differentiable Monte-Carlo Estimator.\u201d arXiv. Arguments x (Variable) - Variable to transform. Return (Variable) - Tensor of 1, but it's gradient is the gradient of x. Example loss = (magic_box(cum_log_probs) * advantages).mean() # loss is the mean advantage loss.backward()","title":"magic_box"},{"location":"docs/learn2learn.models/","text":"learn2learn.models ConvBase ConvBase(output_size, hidden=64, channels=1, max_pool=False, layers=4, max_pool_factor=1.0) NOTE: Omniglot: hidden=64, channels=1, no max_pool MiniImagenet: hidden=32, channels=3, max_pool","title":"learn2learn.models"},{"location":"docs/learn2learn.models/#learn2learnmodels","text":"","title":"learn2learn.models"},{"location":"docs/learn2learn.models/#convbase","text":"ConvBase(output_size, hidden=64, channels=1, max_pool=False, layers=4, max_pool_factor=1.0) NOTE: Omniglot: hidden=64, channels=1, no max_pool MiniImagenet: hidden=32, channels=3, max_pool","title":"ConvBase"},{"location":"docs/learn2learn.text/","text":"NewsClassification NewsClassification(self, root, train=True, transform=None, download=False) [Source] Description References TODO: Cite ... Arguments Example","title":"NewsClassification"},{"location":"docs/learn2learn.text/#newsclassification","text":"NewsClassification(self, root, train=True, transform=None, download=False) [Source] Description References TODO: Cite ... Arguments Example","title":"NewsClassification"},{"location":"docs/learn2learn.vision/","text":"learn2learn.vision.models Description A set of commonly used models for meta-learning vision tasks. OmniglotFC OmniglotFC(self, input_size, output_size, sizes=None) [Source] Description References TODO: Cite ... Arguments Example OmniglotCNN OmniglotCNN(self, output_size=5, hidden_size=64, layers=4) Source Description References TODO: Cite MAML? Or wherever MAML gets their network from. (Matching nets?) Arguments Example learn2learn.vision.datasets Description A set of transformations commonly used in meta-learning vision tasks. FullOmniglot FullOmniglot(self, root, transform=None, target_transform=None, download=False) [Source] Description References TODO: Cite Lake et al. Arguments Example learn2learn.vision.transforms Description A set of transformations commonly used in meta-learning vision tasks. RandomDiscreteRotation RandomDiscreteRotation(self, degrees, *args, **kwargs) [Source] Description References TODO: Cite ... Arguments Example","title":"learn2learn.vision"},{"location":"docs/learn2learn.vision/#learn2learnvisionmodels","text":"Description A set of commonly used models for meta-learning vision tasks.","title":"learn2learn.vision.models"},{"location":"docs/learn2learn.vision/#omniglotfc","text":"OmniglotFC(self, input_size, output_size, sizes=None) [Source] Description References TODO: Cite ... Arguments Example","title":"OmniglotFC"},{"location":"docs/learn2learn.vision/#omniglotcnn","text":"OmniglotCNN(self, output_size=5, hidden_size=64, layers=4) Source Description References TODO: Cite MAML? Or wherever MAML gets their network from. (Matching nets?) Arguments Example","title":"OmniglotCNN"},{"location":"docs/learn2learn.vision/#learn2learnvisiondatasets","text":"Description A set of transformations commonly used in meta-learning vision tasks.","title":"learn2learn.vision.datasets"},{"location":"docs/learn2learn.vision/#fullomniglot","text":"FullOmniglot(self, root, transform=None, target_transform=None, download=False) [Source] Description References TODO: Cite Lake et al. Arguments Example","title":"FullOmniglot"},{"location":"docs/learn2learn.vision/#learn2learnvisiontransforms","text":"Description A set of transformations commonly used in meta-learning vision tasks.","title":"learn2learn.vision.transforms"},{"location":"docs/learn2learn.vision/#randomdiscreterotation","text":"RandomDiscreteRotation(self, degrees, *args, **kwargs) [Source] Description References TODO: Cite ... Arguments Example","title":"RandomDiscreteRotation"},{"location":"docs/learn2learn.vision.models/","text":"learn2learn.models ConvBase ConvBase(output_size, hidden=64, channels=1, max_pool=False, layers=4, max_pool_factor=1.0) NOTE: Omniglot: hidden=64, channels=1, no max_pool MiniImagenet: hidden=32, channels=3, max_pool","title":"learn2learn.vision.models"},{"location":"docs/learn2learn.vision.models/#learn2learnmodels","text":"","title":"learn2learn.models"},{"location":"docs/learn2learn.vision.models/#convbase","text":"ConvBase(output_size, hidden=64, channels=1, max_pool=False, layers=4, max_pool_factor=1.0) NOTE: Omniglot: hidden=64, channels=1, no max_pool MiniImagenet: hidden=32, channels=3, max_pool","title":"ConvBase"},{"location":"tutorials/getting_started/","text":"Getting Started L2L is a meta-learning library providing three levels of functionality for users. At a high level, there are many examples using meta-learning algorithms to train on a myriad of datasets/environments. At a mid level, it provides a functional interface for several popular meta-learning algorithms as well as a data loader to make it easier to import other data sets. At a low level, it provides extended functionality for modules. What is meta-learning? Machine learning is typically concerned with the process of adapting an agent or model to perform well on a given task \\mathcal{T} . If any aspect of \\mathcal{T} changes then we must begin training anew; however, it is easy to imagine several situations where we may want to teach an agent or train a model to perform several tasks that are very similar in nature or skill required. In this case, we would like to extract \"general\" knowledge from training on an individual task to reduce the amount of time and data needed to train on a subsequent later task. To formalize this notion we assume that the tasks trained on are i.i.d. samples \\{\\mathcal{T}_{1} \\dotsb \\mathcal{T}_{m}\\} , and we have a loss function \\mathcal{L} defined for all \\mathcal{T} . We can then phrase the problem of meta-learning a few ways. One way is as k-shot learning, where we aim to find a model or policy M that minimizes E_{\\mathcal{T} }[\\mathcal{L}(M_{k}(\\mathcal{T}))] , where M_{k} denotes the model M after training on \\mathcal{T} for k episodes. For more information about specific meta-learning algorithms, please refer to the appropriate tutorial. How to Use L2L Installing A pip package is available, updated periodically. Use the command: pip install learn2learn For the most update-to-date version clone the repository and use: pip install -e . A list of dependencies is maintained and periodically updated in requirements-dev.txt. To install them all use pip install -r requirements-dev.txt Important: As learn2learn is still in the developmental stage, breaking changes are likely to occur. If you encounter a problem, feel free to an open an issue and we'll look into it. Source Files Examples of learn2learn in action can be found here . The source code for algorithm implementations is also available here .","title":"Getting Started"},{"location":"tutorials/getting_started/#getting-started","text":"L2L is a meta-learning library providing three levels of functionality for users. At a high level, there are many examples using meta-learning algorithms to train on a myriad of datasets/environments. At a mid level, it provides a functional interface for several popular meta-learning algorithms as well as a data loader to make it easier to import other data sets. At a low level, it provides extended functionality for modules.","title":"Getting Started"},{"location":"tutorials/getting_started/#what-is-meta-learning","text":"Machine learning is typically concerned with the process of adapting an agent or model to perform well on a given task \\mathcal{T} . If any aspect of \\mathcal{T} changes then we must begin training anew; however, it is easy to imagine several situations where we may want to teach an agent or train a model to perform several tasks that are very similar in nature or skill required. In this case, we would like to extract \"general\" knowledge from training on an individual task to reduce the amount of time and data needed to train on a subsequent later task. To formalize this notion we assume that the tasks trained on are i.i.d. samples \\{\\mathcal{T}_{1} \\dotsb \\mathcal{T}_{m}\\} , and we have a loss function \\mathcal{L} defined for all \\mathcal{T} . We can then phrase the problem of meta-learning a few ways. One way is as k-shot learning, where we aim to find a model or policy M that minimizes E_{\\mathcal{T} }[\\mathcal{L}(M_{k}(\\mathcal{T}))] , where M_{k} denotes the model M after training on \\mathcal{T} for k episodes. For more information about specific meta-learning algorithms, please refer to the appropriate tutorial.","title":"What is meta-learning?"},{"location":"tutorials/getting_started/#how-to-use-l2l","text":"","title":"How to Use L2L"},{"location":"tutorials/getting_started/#installing","text":"A pip package is available, updated periodically. Use the command: pip install learn2learn For the most update-to-date version clone the repository and use: pip install -e . A list of dependencies is maintained and periodically updated in requirements-dev.txt. To install them all use pip install -r requirements-dev.txt Important: As learn2learn is still in the developmental stage, breaking changes are likely to occur. If you encounter a problem, feel free to an open an issue and we'll look into it.","title":"Installing"},{"location":"tutorials/getting_started/#source-files","text":"Examples of learn2learn in action can be found here . The source code for algorithm implementations is also available here .","title":"Source Files"}]}